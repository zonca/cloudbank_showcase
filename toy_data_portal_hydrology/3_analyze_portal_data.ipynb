{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 - Explore portal data from JupyterHub\n",
    "\n",
    "Goal: in the JupyterHub from step 1, call the toy data portal API, download a NetCDF dataset from the bucket, open it, and make a simple plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "- JupyterHub from step 1 is running (use the credentials printed during deployment).\n",
    "- The portal from step 2 is running and already has at least one NetCDF file uploaded (see the screenshots in step 2 and the sample download links in `README.md`).\n",
    "- The portal bucket was made readable for everyone (the step that added `allUsers` as `storage.objectViewer`).\n",
    "- Note the portal external IP from step 2. Set `PORTAL_BASE` below to `http://<EXTERNAL-IP>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q requests pandas xarray netCDF4 matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "PORTAL_BASE = os.environ.get(\"PORTAL_BASE\", \"http://<EXTERNAL-IP>\").rstrip('/')\n",
    "PORTAL_API = f\"{PORTAL_BASE}/api\"\n",
    "PORTAL_BASE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List datasets from the portal API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, pandas as pd\n",
    "\n",
    "resp = requests.get(f\"{PORTAL_API}/datasets\", timeout=30)\n",
    "resp.raise_for_status()\n",
    "datasets = resp.json().get(\"datasets\", [])\n",
    "print(f\"Found {len(datasets)} dataset entries\")\n",
    "pd.DataFrame(datasets)[[\"id\", \"format\", \"bytes\", \"location\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a NetCDF entry to download. This example grabs the first entry that looks like a NetCDF file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "def choose_dataset(entries):\n",
    "    if not entries:\n",
    "        raise ValueError(\"No datasets available. Upload a NetCDF file first.\")\n",
    "    for item in entries:\n",
    "        fmt = (item.get(\"format\") or \"\").lower()\n",
    "        if \"netcdf\" in fmt or str(item.get(\"id\", \"\")).endswith('.nc'):\n",
    "            return item\n",
    "    return entries[0]\n",
    "\n",
    "selected = choose_dataset(datasets)\n",
    "selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the file\n",
    "The portal records the storage path as `gs://...`. Convert that to an HTTPS URL so we can fetch it anonymously (thanks to the public read permission)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_url = selected[\"location\"].replace(\"gs://\", \"https://storage.googleapis.com/\")\n",
    "local_path = Path(\"data\") / Path(selected[\"location\"]).name\n",
    "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Downloading from:\", download_url)\n",
    "\n",
    "with requests.get(download_url, stream=True, timeout=300) as r:\n",
    "    r.raise_for_status()\n",
    "    with open(local_path, \"wb\") as f:\n",
    "        for chunk in r.iter_content(chunk_size=1 << 20):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "local_path, local_path.stat().st_size / (1024 * 1024)
"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NetCDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "ds = xr.open_dataset(local_path)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the global attributes that were stored in the file (these were also used to populate the portal metadata JSON)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a quick plot\n",
    "Pick the first numeric data variable, slice a small portion to keep the plot light, and draw a simple line plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_vars = [name for name, da in ds.data_vars.items() if getattr(da, 'dtype', None) and da.dtype.kind in 'if']\n",
    "if not numeric_vars:\n",
    "    raise ValueError(\"No numeric variables found to plot.\")\n",
    "var = numeric_vars[0]\n",
    "da = ds[var]\n",
    "\n",
    "# Slice a small piece from each dimension\n",
    "sliced = da\n",
    "for dim in da.dims:\n",
    "    sliced = sliced.isel({dim: slice(0, min(50, da.sizes[dim]))})\n",
    "squeezed = sliced.squeeze()\n",
    "\n",
    "ax = squeezed.plot(figsize=(8, 4))\n",
    "plt.title(f\"Sample of '{var}'\")\n",
    "plt.show()\n",
    "\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next ideas: explore more variables, compare datasets, or join this with other sources inside the same notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
