{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2fe11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q requests pandas xarray matplotlib netCDF4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fc0e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "PORTAL_BASE = \"http://toy-portal.portal.svc.cluster.local\"  # set to portal service (in-cluster DNS or external IP)\n",
    "LOCAL_NETCDF = None  # optional local fallback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fed171",
   "metadata": {},
   "source": [
    "# 3 - Explore portal data from JupyterHub\n",
    "\n",
    "What this does:\n",
    "- Lists datasets from the toy data portal API.\n",
    "- Falls back to a local NetCDF if `LOCAL_NETCDF` is set or the portal is unreachable.\n",
    "- Downloads the chosen file (if not local), opens it with xarray, prints metadata, and saves a quick 2D scatter plot (lat/lon colored by a data variable).\n",
    "- Kept in sync with the notebook via Jupytext (`ipynb` and `py:percent`).\n",
    "- Executed notebook output: https://gist.github.com/zonca/110eface6429e7b91160f893c214417c\n",
    "\n",
    "Configure at the top of the notebook:\n",
    "- `PORTAL_BASE`: required unless `LOCAL_NETCDF` is set (inside the cluster use `http://toy-portal.portal.svc.cluster.local`; from outside use the portal external IP like `http://35.x.x.x`).\n",
    "- `LOCAL_NETCDF`: optional local NetCDF path to skip the portal download.\n",
    "- Plot is saved to `plot.png` in the working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdbe74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import xarray as xr\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bb4771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LOCAL_NETCDF = os.environ.get(\"LOCAL_NETCDF\", LOCAL_NETCDF)\n",
    "\n",
    "if LOCAL_NETCDF:\n",
    "    # Local file overrides portal API lookups\n",
    "    PORTAL_API = None\n",
    "    print(f\"Local NetCDF override: {LOCAL_NETCDF}\")\n",
    "elif PORTAL_BASE:\n",
    "    PORTAL_BASE = PORTAL_BASE.rstrip(\"/\")\n",
    "    print(f\"Portal base: {PORTAL_BASE}\")\n",
    "    PORTAL_API = f\"{PORTAL_BASE}/api\"\n",
    "else:\n",
    "    raise SystemExit(\n",
    "        \"Set LOCAL_NETCDF to a local file path, or set PORTAL_BASE to the portal URL (for example http://35.x.x.x).\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_datasets() -> tuple[List[Dict[str, Any]], str | None]:\n",
    "    \"\"\"Return dataset entries from the portal API, or a local fallback if provided.\"\"\"\n",
    "    datasets: List[Dict[str, Any]] = []\n",
    "    portal_error: str | None = None\n",
    "    if PORTAL_API:\n",
    "        try:\n",
    "            resp = requests.get(f\"{PORTAL_API}/datasets\", timeout=30)\n",
    "            resp.raise_for_status()\n",
    "            datasets = resp.json().get(\"datasets\", [])\n",
    "        except Exception as exc:  # pragma: no cover - best effort\n",
    "            portal_error = str(exc)\n",
    "\n",
    "    if portal_error:\n",
    "        print(f\"Portal API error (will fall back to LOCAL_NETCDF if set): {portal_error}\")\n",
    "\n",
    "    if not datasets and LOCAL_NETCDF:\n",
    "        p = Path(LOCAL_NETCDF).expanduser().resolve()\n",
    "        datasets = [\n",
    "            {\n",
    "                \"id\": p.name,\n",
    "                \"format\": \"NetCDF\",\n",
    "                \"bytes\": p.stat().st_size if p.exists() else None,\n",
    "                \"location\": f\"file://{p}\",\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    print(f\"Found {len(datasets)} dataset entries\")\n",
    "    if datasets:\n",
    "        print(pd.DataFrame(datasets)[[\"id\", \"format\", \"bytes\", \"location\"]].head())\n",
    "    return datasets, portal_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329433e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_dataset(entries: List[Dict[str, Any]], portal_error: str | None = None) -> Dict[str, Any]:\n",
    "    if not entries:\n",
    "        msg = \"No datasets available. Upload a NetCDF file first.\"\n",
    "        if portal_error:\n",
    "            msg += (\n",
    "                f\" The portal API was unreachable/erroring: {portal_error}. \"\n",
    "                \"If the portal is down, set LOCAL_NETCDF to a local file path to proceed.\"\n",
    "            )\n",
    "        raise ValueError(msg)\n",
    "    for item in entries:\n",
    "        fmt = (item.get(\"format\") or \"\").lower()\n",
    "        if \"netcdf\" in fmt or str(item.get(\"id\", \"\")).endswith(\".nc\"):\n",
    "            return item\n",
    "    return entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04844a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dataset(meta: Dict[str, Any]) -> Path:\n",
    "    location = meta[\"location\"]\n",
    "    if location.startswith(\"file://\"):\n",
    "        local_path = Path(location.replace(\"file://\", \"\"))\n",
    "        print(f\"Using local file: {local_path}\")\n",
    "        return local_path\n",
    "\n",
    "    download_url = location.replace(\"gs://\", \"https://storage.googleapis.com/\")\n",
    "    local_path = Path(\"data\") / Path(location).name\n",
    "    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"Downloading from: {download_url}\")\n",
    "    with requests.get(download_url, stream=True, timeout=300) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(local_path, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1 << 20):\n",
    "                if chunk:\n",
    "                    f.write(chunk)\n",
    "    print(f\"Saved to {local_path} ({local_path.stat().st_size / (1024 * 1024):.1f} MiB)\")\n",
    "    return local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf1fcea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_dataset(path: Path) -> xr.Dataset:\n",
    "    ds = xr.open_dataset(path)\n",
    "    print(\"Dataset summary:\")\n",
    "    print(ds)\n",
    "    print(\"\\nGlobal attributes:\")\n",
    "    print(ds.attrs)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c900c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_variable(ds: xr.Dataset, var: str, output: Path) -> Path:\n",
    "    \"\"\"Make a small, colorful 2D scatter using lat/lon for the requested variable.\"\"\"\n",
    "    da = ds[var]\n",
    "    if \"lat\" in ds and \"lon\" in ds and \"feature_id\" in da.dims:\n",
    "        n = min(75000, da.sizes.get(\"feature_id\", 0))\n",
    "        lat = ds[\"lat\"].isel(feature_id=slice(0, n)).values\n",
    "        lon = ds[\"lon\"].isel(feature_id=slice(0, n)).values\n",
    "        vals = da.isel(feature_id=slice(0, n)).values\n",
    "        mask = np.isfinite(lat) & np.isfinite(lon) & np.isfinite(vals)\n",
    "        lat, lon, vals = lat[mask], lon[mask], vals[mask]\n",
    "        if vals.size == 0:\n",
    "            raise ValueError(\"No finite values to plot.\")\n",
    "        vmin = np.nanpercentile(vals, 2)\n",
    "        vmax = np.nanpercentile(vals, 98)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sc = plt.scatter(lon, lat, c=vals, cmap=\"plasma\", s=2, linewidths=0, vmin=vmin, vmax=vmax)\n",
    "        plt.colorbar(sc, label=f\"{var} (clipped 2â€“98th pct)\")\n",
    "        plt.xlabel(\"Longitude\")\n",
    "        plt.ylabel(\"Latitude\")\n",
    "        plt.title(f\"{var} across reaches (first {n} points)\")\n",
    "    else:\n",
    "        # Fallback to a 1D slice if lat/lon are not present\n",
    "        sliced = da\n",
    "        for dim in da.dims:\n",
    "            sliced = sliced.isel({dim: slice(0, min(50, da.sizes[dim]))})\n",
    "        squeezed = sliced.squeeze()\n",
    "        squeezed.plot(figsize=(8, 4))\n",
    "        plt.title(f\"Sample of '{var}'\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    output.parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(output)\n",
    "    # Show only on interactive backends (not when running headless)\n",
    "    if not plt.get_backend().lower().endswith(\"agg\"):\n",
    "        plt.show()\n",
    "    plt.close()\n",
    "    print(f\"Saved plot to {output}\")\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd885f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets, portal_error = list_datasets()\n",
    "selected = choose_dataset(datasets, portal_error)\n",
    "print(f\"Selected dataset: {selected.get('id')}\")\n",
    "local_path = download_dataset(selected)\n",
    "ds = inspect_dataset(local_path)\n",
    "preferred = [\"So\", \"TopWdth\", \"TopWdthCC\", \"order\", \"Qi\", \"nCC\"]\n",
    "plotted_any = False\n",
    "for var in preferred:\n",
    "    if var in ds:\n",
    "        plot_variable(ds, var, Path(f\"plot_{var.lower()}.png\"))\n",
    "        plotted_any = True\n",
    "if not plotted_any:\n",
    "    numeric_vars = [name for name, da in ds.data_vars.items() if getattr(da, \"dtype\", None) and da.dtype.kind in \"if\"]\n",
    "    if numeric_vars:\n",
    "        plot_variable(ds, numeric_vars[0], Path(\"plot_numeric.png\"))"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
